{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: CUDAdrv.jl failed to initialize, GPU functionality unavailable (set JULIA_CUDA_SILENT or JULIA_CUDA_VERBOSE to silence or expand this message)\n",
      "└ @ CUDAdrv C:\\Users\\mclau\\.julia\\packages\\CUDAdrv\\b1mvw\\src\\CUDAdrv.jl:67\n"
     ]
    }
   ],
   "source": [
    "using ReinforcementLearning\n",
    "using Flux\n",
    "using Statistics\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CartPoleEnv{Float32}(gravity=9.8,masscart=1.0,masspole=0.1,totalmass=1.1,halflength=0.5,polemasslength=0.05,forcemag=10.0,tau=0.02,thetathreshold=0.20943952,xthreshold=2.4,max_steps=200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CartPoleEnv(;T=Float32, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(4, 28, relu), Dense(28, 28, relu), Dense(28, 2))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(Dense(4, 28, relu),\n",
    "              Dense(28, 28, relu),\n",
    "              Dense(28, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(true, true, 1.0, 0.95, 0.01, 32, Any[], 150, 4, 2, 1.0, 20, Chain(Dense(4, 28, relu), Dense(28, 28, relu), Dense(28, 2)), Chain(Dense(4, 28, relu), Dense(28, 28, relu), Dense(28, 2)), var\"#loss#3\"{Chain{Tuple{Dense{typeof(relu),Array{Float32,2},Array{Float32,1}},Dense{typeof(relu),Array{Float32,2},Array{Float32,1}},Dense{typeof(identity),Array{Float32,2},Array{Float32,1}}}}}(Chain(Dense(4, 28, relu), Dense(28, 28, relu), Dense(28, 2))), Params([Float32[-0.25155243 -0.24704061 -0.40773025 -0.05038451; 0.16301416 -0.08474014 0.18600604 -0.2858451; … ; 0.12673984 0.20115957 -0.31452468 0.044402678; 0.11282529 0.3666783 -0.1424651 0.2934431], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.22969203 -0.113347314 … -0.25406268 -0.146727; 0.31591117 -0.069342606 … 0.29623914 0.22597447; … ; -0.25261605 0.2183456 … -0.2206922 -0.30897868; 0.15169539 -0.23114303 … 0.3160519 0.05246597], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.26616418 0.41406718 … 0.20542441 -0.2658638; -0.012576624 0.038617518 … -0.12744738 0.23391244], Float32[0.0, 0.0]]), ADAM(0.001, (0.9, 0.8), IdDict{Any,Any}()))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=DQN(0.95,0.01,32,150,4,2,1.0,20,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 | Score: 12.0 \n",
      "Episode: 2 | Score: 23.0 \n",
      "Episode: 3 | Score: 16.0 \n",
      "Episode: 4 | Score: 16.0 \n",
      "Episode: 5 | Score: 11.0 \n",
      "Episode: 6 | Score: 15.0 \n",
      "Episode: 7 | Score: 27.0 \n",
      "Episode: 8 | Score: 30.0 \n",
      "Episode: 9 | Score: 14.0 \n",
      "Episode: 10 | Score: 21.0 \n",
      "Episode: 11 | Score: 11.0 \n",
      "Episode: 12 | Score: 12.0 \n",
      "Episode: 13 | Score: 14.0 \n",
      "Episode: 14 | Score: 19.0 \n",
      "Episode: 15 | Score: 16.0 \n",
      "Episode: 16 | Score: 11.0 \n",
      "Episode: 17 | Score: 13.0 \n",
      "Episode: 18 | Score: 12.0 \n",
      "Episode: 19 | Score: 10.0 \n",
      "Episode: 20 | Score: 18.0 \n",
      "Episode: 21 | Score: 15.0 \n",
      "Episode: 22 | Score: 11.0 \n",
      "Episode: 23 | Score: 14.0 \n",
      "Episode: 24 | Score: 18.0 \n",
      "Episode: 25 | Score: 17.0 \n",
      "Episode: 26 | Score: 16.0 \n",
      "Episode: 27 | Score: 16.0 \n",
      "Episode: 28 | Score: 21.0 \n",
      "Episode: 29 | Score: 15.0 \n",
      "Episode: 30 | Score: 11.0 \n",
      "Episode: 31 | Score: 13.0 \n",
      "Episode: 32 | Score: 11.0 \n",
      "Episode: 33 | Score: 12.0 \n",
      "Episode: 34 | Score: 17.0 \n",
      "Episode: 35 | Score: 19.0 \n",
      "Episode: 36 | Score: 11.0 \n",
      "Episode: 37 | Score: 13.0 \n",
      "Episode: 38 | Score: 17.0 \n",
      "Episode: 39 | Score: 11.0 \n",
      "Episode: 40 | Score: 13.0 \n",
      "Episode: 41 | Score: 13.0 \n",
      "Episode: 42 | Score: 10.0 \n",
      "Episode: 43 | Score: 13.0 \n",
      "Episode: 44 | Score: 16.0 \n",
      "Episode: 45 | Score: 20.0 \n",
      "Episode: 46 | Score: 14.0 \n",
      "Episode: 47 | Score: 17.0 \n",
      "Episode: 48 | Score: 15.0 \n",
      "Episode: 49 | Score: 15.0 \n",
      "Episode: 50 | Score: 17.0 \n",
      "Episode: 51 | Score: 16.0 \n",
      "Episode: 52 | Score: 11.0 \n",
      "Episode: 53 | Score: 17.0 \n",
      "Episode: 54 | Score: 11.0 \n",
      "Episode: 55 | Score: 14.0 \n",
      "Episode: 56 | Score: 18.0 \n",
      "Episode: 57 | Score: 14.0 \n",
      "Episode: 58 | Score: 22.0 \n",
      "Episode: 59 | Score: 17.0 \n",
      "Episode: 60 | Score: 11.0 \n",
      "Episode: 61 | Score: 17.0 \n",
      "Episode: 62 | Score: 14.0 \n",
      "Episode: 63 | Score: 17.0 \n",
      "Episode: 64 | Score: 12.0 \n",
      "Episode: 65 | Score: 15.0 \n",
      "Episode: 66 | Score: 13.0 \n",
      "Episode: 67 | Score: 11.0 \n",
      "Episode: 68 | Score: 17.0 \n",
      "Episode: 69 | Score: 11.0 \n",
      "Episode: 70 | Score: 19.0 \n",
      "Episode: 71 | Score: 22.0 \n",
      "Episode: 72 | Score: 15.0 \n",
      "Episode: 73 | Score: 18.0 \n",
      "Episode: 74 | Score: 15.0 \n",
      "Episode: 75 | Score: 17.0 \n",
      "Episode: 76 | Score: 12.0 \n",
      "Episode: 77 | Score: 12.0 \n",
      "Episode: 78 | Score: 14.0 \n",
      "Episode: 79 | Score: 13.0 \n",
      "Episode: 80 | Score: 13.0 \n",
      "Episode: 81 | Score: 16.0 \n",
      "Episode: 82 | Score: 17.0 \n",
      "Episode: 83 | Score: 10.0 \n",
      "Episode: 84 | Score: 14.0 \n",
      "Episode: 85 | Score: 14.0 \n",
      "Episode: 86 | Score: 12.0 \n",
      "Episode: 87 | Score: 29.0 \n",
      "Episode: 88 | Score: 14.0 \n",
      "Episode: 89 | Score: 13.0 \n",
      "Episode: 90 | Score: 10.0 \n",
      "Episode: 91 | Score: 12.0 \n",
      "Episode: 92 | Score: 16.0 \n",
      "Episode: 93 | Score: 15.0 \n",
      "Episode: 94 | Score: 12.0 \n",
      "Episode: 95 | Score: 15.0 \n",
      "Episode: 96 | Score: 12.0 \n",
      "Episode: 97 | Score: 13.0 \n",
      "Episode: 98 | Score: 11.0 \n",
      "Episode: 99 | Score: 15.0 \n",
      "Episode: 100 | Score: 12.0 \n",
      "Episode: 101 | Score: 11.0 Last 100 episodes mean score: 14.91\n",
      "Episode: 102 | Score: 10.0 Last 100 episodes mean score: 14.78\n",
      "Episode: 103 | Score: 9.0 Last 100 episodes mean score: 14.71\n",
      "Episode: 104 | Score: 12.0 Last 100 episodes mean score: 14.67\n",
      "Episode: 105 | Score: 23.0 Last 100 episodes mean score: 14.79\n",
      "Episode: 106 | Score: 12.0 Last 100 episodes mean score: 14.76\n",
      "Episode: 107 | Score: 10.0 Last 100 episodes mean score: 14.59\n",
      "Episode: 108 | Score: 13.0 Last 100 episodes mean score: 14.42\n",
      "Episode: 109 | Score: 10.0 Last 100 episodes mean score: 14.38\n",
      "Episode: 110 | Score: 28.0 Last 100 episodes mean score: 14.45\n",
      "Episode: 111 | Score: 14.0 Last 100 episodes mean score: 14.48\n",
      "Episode: 112 | Score: 20.0 Last 100 episodes mean score: 14.56\n",
      "Episode: 113 | Score: 12.0 Last 100 episodes mean score: 14.54\n",
      "Episode: 114 | Score: 17.0 Last 100 episodes mean score: 14.52\n",
      "Episode: 115 | Score: 11.0 Last 100 episodes mean score: 14.47\n",
      "Episode: 116 | Score: 27.0 Last 100 episodes mean score: 14.63\n",
      "Episode: 117 | Score: 28.0 Last 100 episodes mean score: 14.78\n",
      "Episode: 118 | Score: 24.0 Last 100 episodes mean score: 14.9\n",
      "Episode: 119 | Score: 15.0 Last 100 episodes mean score: 14.95\n",
      "Episode: 120 | Score: 15.0 Last 100 episodes mean score: 14.92\n",
      "Episode: 121 | Score: 19.0 Last 100 episodes mean score: 14.96\n",
      "Episode: 122 | Score: 23.0 Last 100 episodes mean score: 15.08\n",
      "Episode: 123 | Score: 12.0 Last 100 episodes mean score: 15.06\n",
      "Episode: 124 | Score: 19.0 Last 100 episodes mean score: 15.07\n",
      "Episode: 125 | Score: 19.0 Last 100 episodes mean score: 15.09\n",
      "Episode: 126 | Score: 15.0 Last 100 episodes mean score: 15.08\n",
      "Episode: 127 | Score: 26.0 Last 100 episodes mean score: 15.18\n",
      "Episode: 128 | Score: 15.0 Last 100 episodes mean score: 15.12\n",
      "Episode: 129 | Score: 17.0 Last 100 episodes mean score: 15.14\n",
      "Episode: 130 | Score: 20.0 Last 100 episodes mean score: 15.23\n",
      "Episode: 131 | Score: 19.0 Last 100 episodes mean score: 15.29\n",
      "Episode: 132 | Score: 18.0 Last 100 episodes mean score: 15.36\n",
      "Episode: 133 | Score: 16.0 Last 100 episodes mean score: 15.4\n",
      "Episode: 134 | Score: 27.0 Last 100 episodes mean score: 15.5\n",
      "Episode: 135 | Score: 37.0 Last 100 episodes mean score: 15.68\n",
      "Episode: 136 | Score: 17.0 Last 100 episodes mean score: 15.74\n",
      "Episode: 137 | Score: 30.0 Last 100 episodes mean score: 15.91\n",
      "Episode: 138 | Score: 14.0 Last 100 episodes mean score: 15.88\n",
      "Episode: 139 | Score: 17.0 Last 100 episodes mean score: 15.94\n",
      "Episode: 140 | Score: 16.0 Last 100 episodes mean score: 15.97\n",
      "Episode: 141 | Score: 20.0 Last 100 episodes mean score: 16.04\n",
      "Episode: 142 | Score: 14.0 Last 100 episodes mean score: 16.08\n",
      "Episode: 143 | Score: 17.0 Last 100 episodes mean score: 16.12\n",
      "Episode: 144 | Score: 15.0 Last 100 episodes mean score: 16.11\n",
      "Episode: 145 | Score: 20.0 Last 100 episodes mean score: 16.11\n",
      "Episode: 146 | Score: 23.0 Last 100 episodes mean score: 16.2\n",
      "Episode: 147 | Score: 14.0 Last 100 episodes mean score: 16.17\n",
      "Episode: 148 | Score: 19.0 Last 100 episodes mean score: 16.21\n",
      "Episode: 149 | Score: 19.0 Last 100 episodes mean score: 16.25\n",
      "Episode: 150 | Score: 18.0 Last 100 episodes mean score: 16.26\n",
      "Episode: 151 | Score: 15.0 Last 100 episodes mean score: 16.25\n",
      "Episode: 152 | Score: 22.0 Last 100 episodes mean score: 16.36\n",
      "Episode: 153 | Score: 18.0 Last 100 episodes mean score: 16.37\n",
      "Episode: 154 | Score: 19.0 Last 100 episodes mean score: 16.45\n",
      "Episode: 155 | Score: 25.0 Last 100 episodes mean score: 16.56\n",
      "Episode: 156 | Score: 21.0 Last 100 episodes mean score: 16.59\n",
      "Episode: 157 | Score: 25.0 Last 100 episodes mean score: 16.7\n",
      "Episode: 158 | Score: 36.0 Last 100 episodes mean score: 16.84\n",
      "Episode: 159 | Score: 14.0 Last 100 episodes mean score: 16.81\n",
      "Episode: 160 | Score: 14.0 Last 100 episodes mean score: 16.84\n",
      "Episode: 161 | Score: 27.0 Last 100 episodes mean score: 16.94\n",
      "Episode: 162 | Score: 21.0 Last 100 episodes mean score: 17.01\n",
      "Episode: 163 | Score: 18.0 Last 100 episodes mean score: 17.02\n",
      "Episode: 164 | Score: 14.0 Last 100 episodes mean score: 17.04\n",
      "Episode: 165 | Score: 15.0 Last 100 episodes mean score: 17.04\n",
      "Episode: 166 | Score: 18.0 Last 100 episodes mean score: 17.09\n",
      "Episode: 167 | Score: 25.0 Last 100 episodes mean score: 17.23\n",
      "Episode: 168 | Score: 22.0 Last 100 episodes mean score: 17.28\n",
      "Episode: 169 | Score: 27.0 Last 100 episodes mean score: 17.44\n",
      "Episode: 170 | Score: 22.0 Last 100 episodes mean score: 17.47\n",
      "Episode: 171 | Score: 28.0 Last 100 episodes mean score: 17.53\n",
      "Episode: 172 | Score: 18.0 Last 100 episodes mean score: 17.56\n",
      "Episode: 173 | Score: 35.0 Last 100 episodes mean score: 17.73\n",
      "Episode: 174 | Score: 24.0 Last 100 episodes mean score: 17.82\n",
      "Episode: 175 | Score: 21.0 Last 100 episodes mean score: 17.86\n",
      "Episode: 176 | Score: 30.0 Last 100 episodes mean score: 18.04\n",
      "Episode: 177 | Score: 24.0 Last 100 episodes mean score: 18.16\n",
      "Episode: 178 | Score: 31.0 Last 100 episodes mean score: 18.33\n",
      "Episode: 179 | Score: 25.0 Last 100 episodes mean score: 18.45\n",
      "Episode: 180 | Score: 19.0 Last 100 episodes mean score: 18.51\n",
      "Episode: 181 | Score: 21.0 Last 100 episodes mean score: 18.56\n",
      "Episode: 182 | Score: 15.0 Last 100 episodes mean score: 18.54\n",
      "Episode: 183 | Score: 18.0 Last 100 episodes mean score: 18.62\n",
      "Episode: 184 | Score: 20.0 Last 100 episodes mean score: 18.68\n",
      "Episode: 185 | Score: 21.0 Last 100 episodes mean score: 18.75\n",
      "Episode: 186 | Score: 10.0 Last 100 episodes mean score: 18.73\n",
      "Episode: 187 | Score: 21.0 Last 100 episodes mean score: 18.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 188 | Score: 11.0 Last 100 episodes mean score: 18.62\n",
      "Episode: 189 | Score: 22.0 Last 100 episodes mean score: 18.71\n",
      "Episode: 190 | Score: 12.0 Last 100 episodes mean score: 18.73\n",
      "Episode: 191 | Score: 21.0 Last 100 episodes mean score: 18.82\n",
      "Episode: 192 | Score: 23.0 Last 100 episodes mean score: 18.89\n",
      "Episode: 193 | Score: 13.0 Last 100 episodes mean score: 18.87\n",
      "Episode: 194 | Score: 16.0 Last 100 episodes mean score: 18.91\n",
      "Episode: 195 | Score: 19.0 Last 100 episodes mean score: 18.95\n",
      "Episode: 196 | Score: 14.0 Last 100 episodes mean score: 18.97\n",
      "Episode: 197 | Score: 23.0 Last 100 episodes mean score: 19.07\n",
      "Episode: 198 | Score: 11.0 Last 100 episodes mean score: 19.07\n",
      "Episode: 199 | Score: 16.0 Last 100 episodes mean score: 19.08\n",
      "Episode: 200 | Score: 21.0 Last 100 episodes mean score: 19.17\n",
      "Episode: 201 | Score: 26.0 Last 100 episodes mean score: 19.32\n",
      "Problem unsolved!\n"
     ]
    }
   ],
   "source": [
    "main_DQN(test,env);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct DQN\n",
    "    TRAIN::Bool\n",
    "    CHANGE::Bool\n",
    "    ϵ::Float64\n",
    "    ϵ_DECAY::Float64\n",
    "    ϵ_MIN::Float64\n",
    "    BATCH_SIZE::Int64\n",
    "    MEMORY\n",
    "    MEM_SIZE::Int64\n",
    "    STATE_SIZE::Int64\n",
    "    ACTION_SIZE::Int64\n",
    "    γ::Float64\n",
    "    C_UPDATE::Int64\n",
    "    model1\n",
    "    model2\n",
    "    loss\n",
    "    ps\n",
    "    opt\n",
    "    \n",
    "    function DQN(ϵ_DECAY::Float64, ϵ_MIN::Float64,BATCH_SIZE::Int64,MEM_SIZE::Int64,STATE_SIZE::Int64,\n",
    "            \n",
    "                 ACTION_SIZE::Int64,γ::Float64,C_UPDATE::Int64, model1)\n",
    "        loss(x,y)=Flux.mse(model1(x), y)\n",
    "        \n",
    "        new(true, true, 1.0f0, ϵ_DECAY, ϵ_MIN, BATCH_SIZE, [], MEM_SIZE, STATE_SIZE, ACTION_SIZE,γ,C_UPDATE,\n",
    "            \n",
    "            model1, deepcopy(model1),loss,Flux.params(model1), ADAM(0.001, (0.9, 0.8)))\n",
    "    end\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_DQN (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Fonctions élémentaires\n",
    "\n",
    "#OK\n",
    "function action(dqn::DQN,state::Array{Float32,1})\n",
    "\n",
    "  if rand() <= dqn.ϵ && dqn.TRAIN\n",
    "        \n",
    "    return rand(1:dqn.ACTION_SIZE)\n",
    "\n",
    "  end\n",
    "\n",
    "\n",
    "\n",
    "  act_values = dqn.model1(state)\n",
    "\n",
    "  return Flux.argmax(act_values)\n",
    "    \n",
    "end\n",
    "\n",
    "#OK\n",
    "function update_ϵ!(dqn::DQN)\n",
    "    \n",
    "    x = dqn.ϵ*dqn.ϵ_DECAY\n",
    "    \n",
    "    if x < dqn.ϵ_MIN && dqn.CHANGE\n",
    "        \n",
    "        dqn.ϵ=dqn.ϵ_MIN\n",
    "        \n",
    "        dqn.CHANGE=false\n",
    "        \n",
    "        \n",
    "    elseif dqn.CHANGE\n",
    "        \n",
    "        dqn.ϵ = x\n",
    "        \n",
    "    end\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "#OK\n",
    "function act(action::Int64, env)\n",
    "    \n",
    "    env(action)\n",
    "    \n",
    "    \n",
    "    obs=observe(env)\n",
    "    \n",
    "    get_state(obs), get_reward(obs), get_terminal(obs)\n",
    "    \n",
    "end\n",
    "\n",
    "    \n",
    "#OK    \n",
    "function remember!(dqn::DQN,state::Array{Float32,1}, action::Int64, reward::Float32, next_state::Array{Float32,1}, done::Bool)\n",
    "\n",
    "  if length(dqn.MEMORY) == dqn.MEM_SIZE\n",
    "\n",
    "    deleteat!(dqn.MEMORY, 1)\n",
    "\n",
    "  end\n",
    "\n",
    "  push!(dqn.MEMORY, (state, action, reward, next_state, done))\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function replay!(dqn::DQN)\n",
    "\n",
    "    batch_size = min(dqn.BATCH_SIZE, length(dqn.MEMORY))\n",
    "\n",
    "    minibatch = sample(dqn.MEMORY, batch_size, replace = false)\n",
    "\n",
    "  \n",
    "\n",
    "    x = []\n",
    "\n",
    "    y = []\n",
    "\n",
    "    for (iter, (state, action, reward, next_state, done)) in enumerate(minibatch)\n",
    "\n",
    "        target = reward\n",
    "\n",
    "        if !done\n",
    "\n",
    "            target += dqn.γ * maximum(dqn.model2(next_state))\n",
    "\n",
    "        end\n",
    "\n",
    "\n",
    "\n",
    "        target_f = dqn.model1(state)\n",
    "\n",
    "        target_f[action] = target\n",
    "\n",
    "    \n",
    "\n",
    "        push!(x,state)\n",
    "        \n",
    "\n",
    "        push!(y,action)\n",
    "\n",
    "    end\n",
    "\n",
    "    Flux.train!(dqn.loss,dqn.ps, zip(x, y), dqn.opt)\n",
    "    \n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function copy(iter::Int64, dqn::DQN)\n",
    "    \n",
    "    if iter%dqn.C_UPDATE==0\n",
    "        \n",
    "        dqn.model2 = deepcopy(dqn.model1)\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "    \n",
    "    \n",
    "#Run 1 épisode\n",
    "\n",
    "function episode!(dqn::DQN, env)\n",
    "    \n",
    "    obs_ini=observe(env)\n",
    "    \n",
    "    current_state=get_state(obs_ini)\n",
    "    \n",
    "    \n",
    "    total_reward=0\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while true\n",
    "        \n",
    "        current_action=action(dqn,current_state)\n",
    "        \n",
    "        current_next_state,current_reward,current_done=act(current_action,env)\n",
    "        \n",
    "        \n",
    "        total_reward+=current_reward\n",
    "        \n",
    "        \n",
    "        remember!(dqn, current_state, current_action, current_reward, current_next_state, current_done)\n",
    "        \n",
    "        \n",
    "        current_state=current_next_state\n",
    "        \n",
    "        replay!(dqn)\n",
    "        \n",
    "        update_ϵ!(dqn)\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "        copy(i,dqn)\n",
    "        \n",
    "        if current_done\n",
    "            \n",
    "            break\n",
    "            \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    total_reward\n",
    "    \n",
    "end\n",
    "        \n",
    "\n",
    "#Run DQN algorithm\n",
    "\n",
    "function main_DQN(dqn::DQN, env)\n",
    "    \n",
    "    e = 1\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    while true\n",
    "\n",
    "      reset!(env)\n",
    "\n",
    "      total_reward = episode!(dqn,env)\n",
    "\n",
    "      push!(scores, total_reward)\n",
    "\n",
    "      print(\"Episode: $e | Score: $total_reward \")\n",
    "\n",
    "      if e > 100\n",
    "\n",
    "        last_100_mean = mean(scores[end-99:end])\n",
    "\n",
    "        print(\"Last 100 episodes mean score: $last_100_mean\")\n",
    "\n",
    "        if last_100_mean > 195\n",
    "\n",
    "          println(\"\\nProblem solved!\")\n",
    "\n",
    "          break\n",
    "\n",
    "        end\n",
    "        \n",
    "        if e > 200\n",
    "                \n",
    "          println(\"\\nProblem unsolved!\")\n",
    "                \n",
    "          break\n",
    "        \n",
    "        end\n",
    "\n",
    "      end\n",
    "\n",
    "      println()\n",
    "\n",
    "      e += 1\n",
    "\n",
    "    end\n",
    "    \n",
    "    e, scores\n",
    "    \n",
    "end\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
